{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica : entrenar red nbeuronal para clasifiar imagenes de numeros (28x28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Un tensor es una manera organizada de almacenar un arreglo de datos (EJ : datos tabulares , imagenes ,audio , texto ) puede ser tanto un vector (1 dimension) como una matriz (2 dimensiones) o mas dimensiones para datos mas complejos (imagenes a color , videos )\n",
    "\n",
    "\n",
    "## Ejemplo \n",
    "\n",
    "Arreglo_datos = [[1,2,3],[4,5,6]]\n",
    "Tensor_dedatos = torch.tensor(Arreglo_datos)\n",
    "\n",
    "print(type(Tensor_dedatos))\n",
    "print(Tensor_dedatos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Otra caracteristica es que estos datos pueden ser procesados tanto por gpu como cpu (torch.cuda.is_available())\n",
    "\n",
    "Tensor_dedatos.device #.device para saber donde se esta almacenando\n",
    "\n",
    "##Es posible cambiar el lugar de procesamiento con .to(cpu/cuda)\n",
    "#Tensor_dedatos.to(\"cuda\").device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Al ser un arreglo de datos un Tensor tiene atributos \n",
    "Tensor_dedatos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## En pytorch existen 2 modulos que nos permitesn  cagar sets de datos \n",
    "\n",
    "torch.utils.data.DataLoader # Nos permite crear los bachs para entrenar el modelo (iterar sobre el data set )\n",
    "\n",
    "torch.utils.data.Dataset # Nos permite leer datos que esten almacenados en X lugar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora Conociendo estos 2 conceptos (data set y tensor) podemos pasar a la practica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero importamos las librerias necesarias \n",
    "\n",
    "from torchvision import datasets # descargar el data set (este se encuentra en torch)\n",
    "from torchvision.transforms import ToTensor # trabajar con tensores \n",
    "import matplotlib.pyplot as plt # hacer graficas \n",
    "\n",
    "dataset_28x28 = datasets.MNIST (\n",
    "    \n",
    "    root='./DATASET/', # donde queremos descargar \n",
    "    train=True, # descargar la totalidad de imagenes (cuando trabajamos con un data et para deep learning suele estar dividido en train and validation)\n",
    "    #download=True,\n",
    "    transform=ToTensor() # Transforma las imagenes a tensores para no tener que hacerlo luego \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos el algunos ejemplos del set de datos \n",
    "\n",
    "plot = plt.figure(figsize=(8,8))\n",
    "fila , columna = 3 ,3 \n",
    "\n",
    "for i in range(1 , columna * fila + 1 ):\n",
    "    pick = torch.randint(len(dataset_28x28), size=(1,)).item()\n",
    "    \n",
    "    imgaen , label = dataset_28x28[pick]\n",
    "    \n",
    "    plot.add_subplot(fila,columna,i)\n",
    "    plt.title(str(label))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(imgaen.squeeze() , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencione antes importamos unas 60 mil imganes pero estan no estan particionadas . \n",
    "    siempre que trabajemos en una red nueronal deberemos realizar la partidicion de datos (Entrenamiento , validacion y prueba)\n",
    "    Nornalmente la particion mas grande es la de entrenamiento donde 80% (segun la cantidad de datos que tengamos)\n",
    "    luego tenemos la particion de validacion que se usa a la par que la de entrenamiento para validar que tan bien esta respondiendo al entrenamiento \n",
    "    y fginalmente con la de prueba probamos el modelo ya entrenado con datos que el modelo nunca vio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123) #Es recomendable fijar una semilla de aleatoridad para que al volver a correr el codigo tengamos resultados similares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Para deividir el set de entrenamiento usaremos usaremos Prueba , validacion , entrenamiento = random_split() dentro de ( pondremos el data set y los procentajes  )\n",
    "\n",
    "\n",
    "entrenamiento , validacion , prueba = torch.utils.data.random_split( dataset_28x28 , [0.8 , 0.1 , 0.1] )\n",
    "\n",
    "\n",
    "print(len(entrenamiento))\n",
    "print(len(validacion))\n",
    "print(len(prueba))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con esto podremos empezar con la 'arquitectura' de nuestro modelo \n",
    "\n",
    "recordamnos que las redenes neruonales se deividen en \n",
    "\n",
    "capas de entrada = cantidad de variables que entren , Por ejemplo en este caso entran 28*28 pixeles de entrada = 784 variables aunque deberemos aplanarla entrada \n",
    "\n",
    "capas ocultas = capas donde ocurre el forward propagation\n",
    "\n",
    "capas de salida = segun la cantidad de categorias o necesidades a predecir (10 digitos = 10 neuronas) y usamos softmax para transformar el valor de salida en una probabilidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para crear las redes neuronales en torch usamos nn.Module usando POO es decir nuestras redes neuronales van a ser subclases de nn.Module\n",
    "## Nuestra red neuronal siempre tendra 2 metodos dentro de la subclase \n",
    "    INIT = el cual va a definir su arquitectura (cantidad de neuronas , capas etc) \n",
    "    forward = el cual va a definir como fluyen los valores por la red neuronal (la conexion entre las neuronas) y como se hace cada prediccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn \n",
    "\n",
    "class Redneuronal(nn.Module): ## al escribir nn.module estamos diciendo que la clase redneuronal es hija de module\n",
    "    ## estas 2 lineas de abajo siempre iran ya que son estandar de torch para hacer funcionar la red y inicializar el modelo\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        #Ahora si modemos crear la arquitectura \n",
    "        \n",
    "        self.aplanar = nn.Flatten() # transforma el tensor de (1x28x28) en un vector de (1 , 784)\n",
    "        self.red = nn.Sequential( #Esto en torch es una forma de defininir un patron que indica una secuencia de capas aplicadas en el orden dado\n",
    "            \n",
    "            nn.Linear(28*28 , 15), ##Primero se define la capa de entrada + con cuantas neuronas se va a conectar (capa oculta)\n",
    "            nn.ReLU(), ##Aunque arriba hayamos definido la cantidad de neuronas de la capa oculta nos falta definir su funcion de activacion\n",
    "            nn.Linear(15,10), ## Decimos la capa de salida conectada con las 15 neuronas de la capa oculta \n",
    "          \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self , x ): # X hace referencia al dato de entrada y la secuancia que va a tomar\n",
    "        x = self.aplanar(x)\n",
    "        probabilidades = self.red(x)\n",
    "\n",
    "        return probabilidades\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con la arquitectura podemos crear una instacian de la clase y moverla a la gpu / cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelo = Redneuronal().to('cuda')\n",
    "Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de querer saber la cantidad de pramatros para un modelo podemos uar el metodo parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parametros = sum(p.numel() for p in Modelo.parameters()) #p.numel() accede a la cantidad de perametros por capa si itera y se suma\n",
    "print(Parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo ya listos podemos pasar a entrenar al modelo pero antes dejaremos los sets de entrenamiento y validacion listos \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Creamos 2 data loaders uno para el entrenamiento y otro para la validacion (como dije antes estos se usan al mismo tiempo para corroborar que el entrenamiento este yendo bien)\n",
    "#Shuffle mezcla los datos \n",
    "\n",
    "train_loader = DataLoader( \n",
    "    dataset=entrenamiento,                          \n",
    "    batch_size=64,                      \n",
    "    shuffle=True                       \n",
    "                          )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=validacion,\n",
    "    batch_size=64,\n",
    "    shuffle=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pdoemos preparar los hiperparametros para iniciar el entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "Epochs = 20\n",
    "fun_perdida = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.Adam(Modelo.parameters() , lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora a entrenar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_loop(data_loader, modelo, fun_perdida, optimizador): \n",
    "    train_size = len(data_loader.dataset)\n",
    "    nlotes = len(data_loader)\n",
    "    modelo.train()\n",
    "    \n",
    "    perdida, accuracy = 0, 0\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(data_loader):\n",
    "        x, y = x.to(\"cuda\"), y.to('cuda')\n",
    "        # forward\n",
    "        probabilidad = modelo(x)\n",
    "        # backward\n",
    "        loss = fun_perdida(probabilidad, y)\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "        optimizador.zero_grad()\n",
    "    \n",
    "        perdida += loss.item()\n",
    "        accuracy += (probabilidad.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        # Corrección: mostrar progreso cada 10 lotes\n",
    "        if batch_idx % 10 == 0: \n",
    "            current_loss = loss.item()\n",
    "            processed_samples = (batch_idx + 1) * len(x)\n",
    "            print(f'\\tPerdida: {current_loss:>7f} [{processed_samples:>5d}/{train_size:>5d}]')\n",
    "    \n",
    "    perdida /= nlotes\n",
    "    accuracy /= train_size\n",
    "    print(f'\\t Exactitud/perdida promedio:')\n",
    "    print(f'\\t\\t entrenamiento: {(100*accuracy):>0.2f}% / {perdida:>8f}')  # Aumentar precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(data_loader, modelo, fun_perdida): \n",
    "    val_size = len(data_loader.dataset)\n",
    "    nlotes = len(data_loader)\n",
    "    \n",
    "    modelo.eval()\n",
    "    \n",
    "    perdida_val, accuracy = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader: \n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "            \n",
    "            probabilidad = modelo(X)\n",
    "            \n",
    "            perdida_val += fun_perdida(probabilidad, y).item()\n",
    "            accuracy += (probabilidad.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    perdida_val /= nlotes\n",
    "    accuracy /= val_size\n",
    "    \n",
    "    print(f'\\t\\tValidacion: {(100*accuracy):>0.2f}% / {perdida_val:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Epochs):\n",
    "    print(f'Epoca = {i+1} de {Epochs}')\n",
    "    \n",
    "    entrenamiento_loop(train_loader, Modelo, fun_perdida, optimizador)\n",
    "    \n",
    "    val_loop(val_loader, Modelo, fun_perdida)\n",
    "    \n",
    "print('listo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(model, img , lbl):\n",
    "    # Mover a CUDA para la predicción\n",
    "    img_cuda = img.to('cuda')\n",
    "    \n",
    "    # Generar predicción\n",
    "    logits = model(img_cuda)\n",
    "    y_pred = logits.argmax(1).item()\n",
    "\n",
    "    # Mostrar imagen original y categoría predicha\n",
    "    # Mover de vuelta a CPU para visualización\n",
    "    plt.imshow(img.squeeze().cpu(), cmap=\"gray\")\n",
    "    plt.title(f'Categoría predicha: {y_pred}  , categoria real {lbl}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una imagen del set de prueba\n",
    "img, lbl = prueba[torch.randint(len(prueba), size=(1,)).item()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Y generar la predicción\n",
    "predecir(Modelo, img , lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
